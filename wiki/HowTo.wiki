#summary Usage information.

== Multi-Dimensional Space Specification ==

Before doing anything useful the library needs to know the specification of the multi-dimensional space, that is, how many dimensions there are, and also the precision (number of bits) for each dimension. All this information is captured in a *!MultiDimensionalSpec* object. For compact Hilbert index and inverse calculation there are no limitations on the number of bits. For query building, the total precision must not exceed 62. In general it's a good idea to keep the precision of each dimension as small as possible.

== Fixed Size Bit Vector ==

The coordinates of a point in the multi-dimensional space need to be first represented as a `BitVector[]`. If the coordinates are of type `long` or `BitSet`, the corresponding bit vectors can be created using `BitVectorFactories.OPTIMAL.apply(precision)`, and then using the `copyFrom(long/BitSet)` overloads. There is no direct support for other numerical types such as `BigInteger` right now, so they will have to be converted to `BitSet` first.

To transform from a bit vector back into `long` use `toExactLong`; for `BitSet` use `toBitSet`.

== Compact Hilbert Index Mappings ==

For performance reasons some methods need a pre-allocated output parameter to be passed. To compute an index, call `SpaceFillingCurve.index(point, 0, index)` with a pre-allocated index bit vector of size `MultiDimensionalSpec.sumBitsPerDimension()`.

To extract the coordinates back from an index, use `SpaceFillingCurve.index(index, point)` with a pre-allocated point array.

== Queries ==

To use a multi-dimensional index in a relational database, one needs to store the (big-endian) multi-dimensional index either as the primary key (recommended), or as an indexed column in the table. Then there are a few options to consider:
  * The original coordinates do not necessarily need to be stored in the table. However if the number of ranges and optionally sub-ranges generated for queries tends to be too high, it might be useful to either limit, or not use the sub-ranges feature at all, besides limiting the number of high level ranges, and append to the where clause of the SQL query further filtering of the points to be selected based on their coordinates.
  * There are a few ways to construct the main part of the SQL queries, and which one to use can probably be decided only through experimentation:
    * Some databases such as H2 have special support for array-type prepared statement parameters, in which case redundantly storing the coordinates as separate columns and using the TABLE feature probably works best (see H2's *!TestMultiDimension* and *!MultiDimension* classes).